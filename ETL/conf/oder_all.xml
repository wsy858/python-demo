<?xml version="1.0" encoding="UTF-8"?>
<root>
    <sqoop-shell type="import">
        <param key="connect">jdbc:mysql://192.168.0.154:3306/db_etl</param>   <!-- 数据库连接地址 -->
        <param key="username">root</param><!-- 数据库用户名 -->
        <param key="password">123456</param><!-- 数据库密码 -->
        <param key="table">oderinfo</param><!-- 数据库中待导出的表名 -->
        <param key="hive-database">etl</param> <!-- 指定导入到HIVE的哪个数据库中 -->
        <param key="hive-partition-key">dt</param>   <!-- 通过时间分区 -->
        <param key="hive-partition-value">$dt</param>
        <param key="hive-import"></param>
        <param key="create-hive-table"></param>   <!-- 在hive中新建一张同名同结构的表 -->
        <param key="hive-overwrite"></param> <!-- 覆盖原来以存在的表 -->
        <param key="num-mappers">1</param>   <!-- 使用map任务个数 -->
        <param key="split-by">id</param> <!-- 将表按照id水平切分交给map处理  -->
    </sqoop-shell>
</root>